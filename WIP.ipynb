{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: Counter({2.0: 61, 1.0: 59, 7.0: 20, 3.0: 14, 5.0: 10, 6.0: 6})\n",
      "After SMOTE: Counter({2.0: 61, 3.0: 61, 1.0: 61, 7.0: 61, 5.0: 61, 6.0: 61})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Cargar el dataset desde el archivo CSV\n",
    "try:\n",
    "    data = pd.read_csv('glass.csv')\n",
    "    # Verificar que la columna 'glass_type' exista\n",
    "    if 'glass_type' not in data.columns:\n",
    "        raise ValueError(\"La columna 'glass_type' no se encuentra en el archivo CSV.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: El archivo 'glass.csv' no se encontró. Asegúrate de que el archivo exista en el mismo directorio que el script o proporciona la ruta completa.\")\n",
    "    exit()\n",
    "except pd.errors.EmptyDataError:\n",
    "    print(\"Error: El archivo 'glass.csv' está vacío.\")\n",
    "    exit()\n",
    "except pd.errors.ParserError:\n",
    "    print(\"Error: No se pudo analizar el archivo 'glass.csv'. Verifica el formato del archivo.\")\n",
    "    exit()\n",
    "except ValueError as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# Eliminar filas con NaN en la columna 'glass_type'\n",
    "data = data.dropna(subset=['glass_type'])\n",
    "\n",
    "# Definir las características (X) y las etiquetas (y)\n",
    "X = data.drop('glass_type', axis=1)\n",
    "y = data['glass_type']\n",
    "\n",
    "# Escalar las características\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Imprimir el conteo de clases antes de SMOTE\n",
    "counter = Counter(y_train)\n",
    "print('Before SMOTE:', counter)\n",
    "\n",
    "# Aplicar SMOTE\n",
    "smt = SMOTE(random_state=42)\n",
    "X_train_sm, y_train_sm = smt.fit_resample(X_train, y_train)\n",
    "\n",
    "# Imprimir el conteo de clases después de SMOTE\n",
    "counter = Counter(y_train_sm)\n",
    "print('After SMOTE:', counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-NN ANTES de SMOTE (Hold-Out):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.91      1.00      0.95        10\n",
      "         2.0       0.93      0.87      0.90        15\n",
      "         3.0       1.00      1.00      1.00         3\n",
      "         5.0       0.60      1.00      0.75         3\n",
      "         6.0       1.00      0.67      0.80         3\n",
      "         7.0       1.00      0.89      0.94         9\n",
      "\n",
      "    accuracy                           0.91        43\n",
      "   macro avg       0.91      0.90      0.89        43\n",
      "weighted avg       0.93      0.91      0.91        43\n",
      "\n",
      "Accuracy: 0.9070\n",
      "\n",
      "1-NN ANTES de SMOTE (10-Fold Cross-Validation):\n",
      "Accuracy scores: [0.81818182 0.72727273 0.95454545 0.85714286 0.80952381 0.76190476\n",
      " 0.95238095 0.71428571 0.80952381 0.85714286]\n",
      "Mean accuracy: 0.8262\n",
      "Standard deviation: 0.0783\n",
      "\n",
      "1-NN DESPUÉS de SMOTE (Hold-Out):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.91      1.00      0.95        10\n",
      "         2.0       0.93      0.87      0.90        15\n",
      "         3.0       1.00      1.00      1.00         3\n",
      "         5.0       0.60      1.00      0.75         3\n",
      "         6.0       1.00      0.67      0.80         3\n",
      "         7.0       1.00      0.89      0.94         9\n",
      "\n",
      "    accuracy                           0.91        43\n",
      "   macro avg       0.91      0.90      0.89        43\n",
      "weighted avg       0.93      0.91      0.91        43\n",
      "\n",
      "Accuracy: 0.9070\n",
      "\n",
      "1-NN DESPUÉS de SMOTE (10-Fold Cross-Validation):\n",
      "Accuracy scores: [0.81818182 0.72727273 0.95454545 0.85714286 0.80952381 0.76190476\n",
      " 0.95238095 0.71428571 0.80952381 0.85714286]\n",
      "Mean accuracy: 0.8262\n",
      "Standard deviation: 0.0783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Newton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Newton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 1. Clasificador 1-NN ANTES de SMOTE\n",
    "\n",
    "# Entrenar el clasificador\n",
    "knn = KNeighborsClassifier(n_neighbors=1, metric='euclidean')\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predecir en el conjunto de prueba\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluar el desempeño (Hold-Out)\n",
    "accuracy_holdout = accuracy_score(y_test, y_pred)\n",
    "print(\"1-NN ANTES de SMOTE (Hold-Out):\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"Accuracy: {accuracy_holdout:.4f}\")\n",
    "\n",
    "# Validación cruzada (10-Fold)\n",
    "cv_scores = cross_val_score(knn, X, y, cv=10)\n",
    "print(f\"\\n1-NN ANTES de SMOTE (10-Fold Cross-Validation):\")\n",
    "print(f\"Accuracy scores: {cv_scores}\")\n",
    "print(f\"Mean accuracy: {cv_scores.mean():.4f}\")\n",
    "print(f\"Standard deviation: {cv_scores.std():.4f}\")\n",
    "\n",
    "\n",
    "# 2. Aplicar SMOTE y entrenar 1-NN DESPUÉS de SMOTE\n",
    "\n",
    "smt = SMOTE(random_state=42)\n",
    "X_train_sm, y_train_sm = smt.fit_resample(X_train, y_train)\n",
    "\n",
    "# Entrenar el clasificador con los datos sobremuestreados\n",
    "knn_sm = KNeighborsClassifier(n_neighbors=1, metric='euclidean')\n",
    "knn_sm.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "# Predecir en el conjunto de prueba\n",
    "y_pred_sm = knn_sm.predict(X_test)\n",
    "\n",
    "# Evaluar el desempeño (Hold-Out)\n",
    "accuracy_holdout_sm = accuracy_score(y_test, y_pred_sm)\n",
    "print(\"\\n1-NN DESPUÉS de SMOTE (Hold-Out):\")\n",
    "print(classification_report(y_test, y_pred_sm))\n",
    "print(f\"Accuracy: {accuracy_holdout_sm:.4f}\")\n",
    "\n",
    "# Validación cruzada (10-Fold)\n",
    "cv_scores_sm = cross_val_score(knn_sm, X, y, cv=10) #Usamos X e y originales para la validacion cruzada\n",
    "print(f\"\\n1-NN DESPUÉS de SMOTE (10-Fold Cross-Validation):\")\n",
    "print(f\"Accuracy scores: {cv_scores_sm}\")\n",
    "print(f\"Mean accuracy: {cv_scores_sm.mean():.4f}\")\n",
    "print(f\"Standard deviation: {cv_scores_sm.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      15.0\n",
      "           1       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00      15.0\n",
      "   macro avg       0.00      0.00      0.00      15.0\n",
      "weighted avg       0.00      0.00      0.00      15.0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Newton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Newton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Newton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Newton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Newton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Newton\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Cargar el conjunto de datos Iris\n",
    "try:\n",
    "    iris = pd.read_csv('bezdekIris.csv')\n",
    "    iris = iris[iris['class'].isin(['Iris-setosa', 'versicolor'])]\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: El archivo 'bezdekIris.csv' no se encontró.\")\n",
    "    exit()\n",
    "\n",
    "# Separar características (X) y etiquetas (y)\n",
    "X = iris.drop('class', axis=1)\n",
    "y = iris['class']\n",
    "\n",
    "# Escalar las características\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X) #Escalamos antes de codificar\n",
    "\n",
    "# Codificar las etiquetas de las clases a valores numéricos (0 y 1)\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y) #Codificamos despues de escalar\n",
    "\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba (70/30 Hold-Out)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, learning_rate=0.01, n_iters=1000):\n",
    "        self.lr = learning_rate\n",
    "        self.n_iters = n_iters\n",
    "        self.activation_func = self._unit_step_func\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def _unit_step_func(self, x):\n",
    "        return np.where(x >= 0, 1, 0)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        y_ = np.array([1 if i == 1 else -1 for i in y]) #Ajustamos las etiquetas a 1 y -1\n",
    "\n",
    "        for _ in range(self.n_iters):\n",
    "            for idx, x_i in enumerate(X):\n",
    "                linear_output = np.dot(x_i, self.weights) + self.bias\n",
    "                y_predicted = self.activation_func(linear_output)\n",
    "\n",
    "                update = self.lr * (y_[idx] - y_predicted)\n",
    "                self.weights += update * x_i\n",
    "                self.bias += update\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_output = np.dot(X, self.weights) + self.bias\n",
    "        y_predicted = self.activation_func(linear_output)\n",
    "        return np.where(y_predicted >= 0, 1, 0)\n",
    "\n",
    "\n",
    "# Entrenar el perceptrón\n",
    "perceptron = Perceptron(learning_rate=0.01, n_iters=1000)\n",
    "perceptron.fit(X_train, y_train)\n",
    "\n",
    "# Predecir en el conjunto de prueba\n",
    "y_pred = perceptron.predict(X_test)\n",
    "\n",
    "# Evaluar el desempeño\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
